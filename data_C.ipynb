{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65c48aa9",
   "metadata": {},
   "source": [
    "Since dirctly download csv file does not work well (the Chinese characters can not be recognized). I tried download xlsx file, and load it as df, however, the df does not work either. At last, I download xlsx, save it as csv (choose UTF-8), it works.\n",
    "\n",
    "Remember to download the data to desktop first and change the name (too long).\n",
    "\n",
    "1C is the raw data. 2C is saved as csv. 3C is mannualy changed the question 3 4 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c1e1063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589e0e39",
   "metadata": {},
   "source": [
    "The raw data is downloaded at June 6th, 2023. I made it to cleaned data based on the method I used in 5255 final project (the same to the US data). I used some specific method because of the Chinese characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ccf1771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "raw = pd.read_csv('China/3C_raw_345.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "361ed12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the first row (remain the 0 row) so that the data has only one header row\n",
    "cleaned = raw.iloc[1:].copy()\n",
    "\n",
    "# Convert the 'StartDate' column to a datetime format\n",
    "# cleaned['StartDate'] = pd.to_datetime(cleaned['StartDate'])\n",
    "\n",
    "# Filter the DataFrame to keep only the rows with dates on or after July 1, 2019. I did not use this.\n",
    "# cleaned = cleaned[cleaned['StartDate'] >= '2019-06-30']\n",
    "\n",
    "# Convert the 'Q51' column to a numeric data type\n",
    "cleaned['Q51'] = pd.to_numeric(cleaned['Q51'], errors='coerce')\n",
    "\n",
    "# Filter the DataFrame to remove rows where 'Q51' is greater than 30 or less than 17\n",
    "cleaned = cleaned[(cleaned['Q51'] <= 30) & (cleaned['Q51'] >= 17)].dropna(subset=['Q51'])\n",
    "\n",
    "# First, ensure that the missing values are represented as NaN\n",
    "cleaned[['3', 'Q4', 'Q5']] = cleaned[['3', 'Q4', 'Q5']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Then drop the rows where all three columns are NaN\n",
    "cleaned = cleaned.dropna(subset=['3', 'Q4', 'Q5'], how='all')\n",
    "\n",
    "# Then remove the rows where all three columns are 0\n",
    "cleaned = cleaned[~((cleaned['3'] == 0) & (cleaned['Q4'] == 0) & (cleaned['Q5'] == 0))]\n",
    "\n",
    "# Save the cleaned DataFrame to the 'data' folder\n",
    "cleaned.to_csv('China/C_cleaned_data.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e593f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned data \n",
    "cleaned = pd.read_csv('China/C_cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206bebc6",
   "metadata": {},
   "source": [
    "Add a colunm called covid, the cases after March 2020 are marked 1, the cases before it are marked 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c90773b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'StartDate' to datetime if not already\n",
    "cleaned['StartDate'] = pd.to_datetime(cleaned['StartDate'])\n",
    "\n",
    "# Create 'covid' column\n",
    "cleaned['covid'] = cleaned['StartDate'].apply(lambda x: 1 if x >= pd.to_datetime('2020-03-01') else 0)\n",
    "\n",
    "# save it to .csv file (for checking the data)\n",
    "cleaned.to_csv('China/C_cleaned2.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f4a1d1",
   "metadata": {},
   "source": [
    "X: PCS,PSF,PSM\n",
    "indicators for them:\n",
    "S1-4 (Q77_1,Q77_2,Q77_3,Q77_4),\n",
    "F1-10 (Q50_1_1,Q50_1_3,Q50_1_4,Q50_1_6,Q50_1_7,Q50_1_9,Q50_1_10,Q50_1_11,Q50_1_13,Q50_1_14), \n",
    "M1-10 (Q50_2_1,Q50_2_3,Q50_2_4,Q50_2_6,Q50_2_7,Q50_2_9,Q50_2_10,Q50_2_11,Q50_2_13,Q50_2_14)\n",
    "\n",
    "Y: RRS\n",
    "indicators for it:R1-5 (Q76_1,Q76_2,RRS3,Q76_4,Q76_5)\n",
    "\n",
    "M: AA,including secure(Q20_1), fearful(Q20_2), preoccupied(Q20_3), dimissing(Q20_4) \n",
    "\n",
    "covariates: rela_sta(Q6),age(Q51),gender(1),SES(Q69),duration(Q9),covid(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ece64cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    S1   S2   S3   S4   F1   F2   F3   F4   F5   F6  ...  sec  fea  pre  dis  \\\n",
      "0  6.0  6.0  6.0  6.0  4.0  2.0  3.0  3.0  3.0  4.0  ...  7.0  5.0  4.0  3.0   \n",
      "1  3.0  4.0  2.0  3.0  2.0  2.0  2.0  3.0  4.0  3.0  ...  7.0  1.0  1.0  2.0   \n",
      "2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  4.0  4.0  4.0  4.0   \n",
      "3  2.0  2.0  5.0  4.0  2.0  1.0  2.0  3.0  2.0  1.0  ...  6.0  2.0  2.0  2.0   \n",
      "4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  5.0  5.0  5.0  5.0   \n",
      "\n",
      "   rela_sta   age  gender  SES  duration  covid  \n",
      "0         2  21.0       6    3       一个月      0  \n",
      "1         2  21.0       2    3         4      0  \n",
      "2         2  21.0       6    3        28      0  \n",
      "3         2  22.0       2    3        2年      0  \n",
      "4         1  20.0       6    2         1      0  \n",
      "\n",
      "[5 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned data \n",
    "cleaned2 = pd.read_csv('China/C_cleaned2.csv')\n",
    "\n",
    "# Create a new DataFrame called 'ssea' with some columns from the cleaned data\n",
    "ssea = cleaned2[['Q77_1', 'Q77_2', 'Q77_3', 'Q77_4', 'Q50#1_1', 'Q50#1_3', 'Q50#1_4', 'Q50#1_6', 'Q50#1_7', \n",
    "                'Q50#1_9', 'Q50#1_10', 'Q50#1_11', 'Q50#1_13', 'Q50#1_14', 'Q50#2_1', 'Q50#2_3', 'Q50#2_4', \n",
    "                'Q50#2_6', 'Q50#2_7', 'Q50#2_9', 'Q50#2_10', 'Q50#2_11', 'Q50#2_13', 'Q50#2_14', 'Q76_1', 'Q76_2', \n",
    "                'Q76_3', 'Q76_4', 'Q76_5', 'Q20_1', 'Q20_2', 'Q20_3', 'Q20_4', 'Q6', 'Q51', '1', 'Q69', 'Q9', 'covid']]\n",
    "\n",
    "# Rename the columns to the variable names\n",
    "ssea.columns = ['S1', 'S2', 'S3', 'S4', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10', 'M1', \n",
    "                'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'M10', 'R1', 'R2', 'R3', 'R4', 'R5', \n",
    "                'sec', 'fea', 'pre', 'dis', 'rela_sta', 'age', 'gender', 'SES', 'duration', 'covid']\n",
    "\n",
    "# Output the first few rows of 'ssea' to make sure it looks correct\n",
    "print(ssea.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c096863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# save it to .csv file (for checking the data)\n",
    "ssea.to_csv('China/C_ssea_without_deleting.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d21354",
   "metadata": {},
   "source": [
    "delete rows that have missing value in certain columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f20930f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data \n",
    "ssea2 = pd.read_csv('China/C_ssea_without_deleting.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Drop the rows where all elements are missing.\n",
    "ssea2 = ssea2.dropna(how='all')\n",
    "\n",
    "# Select the first 24 columns and the last 4 columns\n",
    "first_24_columns = ssea2.iloc[:, :24]\n",
    "selected_columns = ssea2.iloc[:, 29:33]\n",
    "\n",
    "# Drop the rows where all elements are missing in the first 24 columns and the last 4 columns.\n",
    "ssea2 = ssea2.loc[~first_24_columns.isnull().all(axis=1) & ~selected_columns.isnull().all(axis=1)]\n",
    "\n",
    "\n",
    "# Save the cleaned data to a new .csv file\n",
    "ssea2.to_csv('China/C_ssea_dropna.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e21eaf1",
   "metadata": {},
   "source": [
    "manage rela_sta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c22e070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data \n",
    "ssea3 = pd.read_csv('China/C_ssea_dropna.csv')\n",
    "\n",
    "# change 'rela_sta' to make it only have values 0 and 1\n",
    "\n",
    "def relationship_transform(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    else:\n",
    "        value_set = set(map(int, value.split(',')))\n",
    "        if value_set.intersection({2, 4, 5, 7}):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "# Create 'rela_sta' based on the 'Q6' column in cleaned_data\n",
    "ssea3['rela_sta'] = ssea3['rela_sta'].apply(relationship_transform)\n",
    "\n",
    "\n",
    "# Save the cleaned data to a new .csv file\n",
    "ssea3.to_csv('China/C_ssea_rela.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5fcd3f",
   "metadata": {},
   "source": [
    "manage gender. Chinese survey has some coding issue. Need to recode first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14e8ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data \n",
    "ssea4 = pd.read_csv('China/C_ssea_rela.csv')\n",
    "\n",
    "# Define a dictionary for the recode\n",
    "recode_dict = {2:2, 3:3, 4:4, 5:5, 7:6, 6:1}\n",
    "\n",
    "# Apply the recode to the 'Gender' column\n",
    "ssea4['gender'] = ssea4['gender'].replace(recode_dict)\n",
    "\n",
    "# Create a new column 'gender_transformed' by combining the certain categories into 1\n",
    "ssea4['gender_trans'] = ssea4['gender'].apply(lambda x: 3 if x in [3, 4, 5, 6] else x if x in [1, 2] else np.nan)\n",
    "\n",
    "# Create dummy variables for 'gender'\n",
    "dummies = pd.get_dummies(ssea4['gender_trans'], prefix='gender',drop_first=True)\n",
    "\n",
    "# Concatenate the original DataFrame and the dummy DataFrame along columns\n",
    "ssea4 = pd.concat([ssea4, dummies], axis=1)\n",
    "\n",
    "# Save the cleaned data to a new .csv file\n",
    "ssea4.to_csv('China/C_ssea_gender.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a06bfd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after checking gender and it's dummy coding varibales, delating them\n",
    "ssea4 = ssea4.drop(['gender', 'gender_trans'], axis=1)\n",
    "\n",
    "# Save the cleaned data to a new .csv file\n",
    "ssea4.to_csv('China/C_ssea_gender2.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9dd13e",
   "metadata": {},
   "source": [
    "copy 'China/C_ssea_gender2.csv' and manage duration manualy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "43d868cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "ssea5 = pd.read_csv('China/C_ssea_duration.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0355d473",
   "metadata": {},
   "source": [
    "scaleing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7e1177dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Create a list of columns to scale\n",
    "columns_to_scale = ['S1', 'S2', 'S3', 'S4', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'M10','sec','fea','pre','dis'\n",
    ",'age','SES','duration']\n",
    "# Copy your dataframe\n",
    "ssea_scaled = ssea5.copy()\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "ssea_scaled[columns_to_scale] = scaler.fit_transform(ssea5[columns_to_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "36ea813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssea_scaled.to_csv('China/C_ssea_scaled.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f0aa1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "ssea6 = pd.read_csv('China/C_ssea_scaled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3f5db193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, replace NaN back to -999, as it's required for the Mplus model\n",
    "ssea6 = ssea6.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fd861d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data to a new .dat file, remove the first row (header)\n",
    "ssea6.to_csv('China/C_ssea.dat', sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4ba694",
   "metadata": {},
   "source": [
    "create mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0cb2ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data\n",
    "ssea7 = pd.read_csv('China/C_ssea_scaled.csv')\n",
    "\n",
    "# Define the columns that belong to each scale\n",
    "pcs_cols = ['S4', 'S1', 'S2', 'S3']\n",
    "rrs_cols = ['R5', 'R1', 'R2', 'R3', 'R4']\n",
    "psf_cols = ['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10']\n",
    "psm_cols = ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'M10']\n",
    "\n",
    "# Compute the mean for each scale\n",
    "ssea7['PCS'] = ssea7[pcs_cols].mean(axis=1)\n",
    "ssea7['RRS'] = ssea7[rrs_cols].mean(axis=1)\n",
    "ssea7['PSF'] = ssea7[psf_cols].mean(axis=1)\n",
    "ssea7['PSM'] = ssea7[psm_cols].mean(axis=1)\n",
    "\n",
    "# Save the new DataFrame to a new .csv file\n",
    "ssea7.to_csv('China/C_ssea_means.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "782257e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "ssea8 = pd.read_csv('China/C_ssea_means.csv')\n",
    "\n",
    "# Now, replace NaN back to -999, as it's required for the Mplus model\n",
    "ssea8 = ssea8.fillna(-999)\n",
    "\n",
    "# Save the cleaned data to a new .dat file, remove the first row (header)\n",
    "ssea8.to_csv('China/C_ssea_mean.dat', sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b022262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "ssea9 = pd.read_csv('China/C_ssea_scaled.csv')\n",
    "\n",
    "# Create a list of columns to scale\n",
    "columns_to_scale = ['R1', 'R2', 'R3', 'R4', 'R5']\n",
    "\n",
    "# Copy your dataframe\n",
    "ssea_scaled2 = ssea9.copy()\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "ssea_scaled2[columns_to_scale] = scaler.fit_transform(ssea9[columns_to_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e79cec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssea_scaled2.to_csv('China/C_ssea_RRSscaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b10f134a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "ssea10 = pd.read_csv('China/C_ssea_RRSscaled.csv')\n",
    "\n",
    "# Now, replace NaN back to -999, as it's required for the Mplus model\n",
    "ssea10 = ssea10.fillna(-999)\n",
    "\n",
    "# Save the cleaned data to a new .dat file, remove the first row (header)\n",
    "ssea10.to_csv('China/C_ssea_RRSscaled.dat', sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51a9f94",
   "metadata": {},
   "source": [
    "Do not scale, create the unscaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7480c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "ssea11 = pd.read_csv('China/C_ssea_duration.csv')\n",
    "# Now, replace NaN back to -999, as it's required for the Mplus model\n",
    "ssea11 = ssea11.fillna(-999)\n",
    "\n",
    "# Save the cleaned data to a new .dat file, remove the first row (header)\n",
    "ssea11.to_csv('China/C_ssea_unscaled.dat', sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1824a719",
   "metadata": {},
   "source": [
    "MIN MAX scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0550716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "ssea12 = pd.read_csv('China/C_ssea_duration.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af3f4e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a list of columns to scale\n",
    "columns_to_scale = ['S1', 'S2', 'S3', 'S4', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10', 'M1', 'M2', 'M3', \n",
    "                    'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'M10','R1', 'R2', 'R3', 'R4','R5','sec','fea','pre','dis'\n",
    ",'age','SES','duration']\n",
    "\n",
    "# Copy your dataframe\n",
    "ssea_scaled = ssea12.copy()\n",
    "\n",
    "# Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "ssea_scaled[columns_to_scale] = scaler.fit_transform(ssea12[columns_to_scale])\n",
    "\n",
    "# save\n",
    "ssea_scaled.to_csv('China/C_ssea_minmax.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87af1b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "ssea13 = pd.read_csv('China/C_ssea_minmax.csv')\n",
    "# Now, replace NaN back to -999, as it's required for the Mplus model\n",
    "ssea13 = ssea13.fillna(-999)\n",
    "\n",
    "# Save the cleaned data to a new .dat file, remove the first row (header)\n",
    "ssea13.to_csv('China/C_ssea_minmax.dat', sep=' ', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
